{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz8DVBGNu0Kr"
      },
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# STEP: Normalization / Scaling\n",
        "# Scale numeric features:\n",
        "#   Age, CGPA, Work/Study Hours, Academic Pressure, Work Pressure, Financial Stress\n",
        "# -------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler  # (Z-score)\n",
        "# from sklearn.preprocessing import MinMaxScaler  # (0â€“1) <-- optional alternative\n",
        "import joblib\n",
        "\n",
        "# Define the intended numeric columns\n",
        "numeric_features = [\n",
        "    \"Age\",\n",
        "    \"CGPA\",\n",
        "    \"Work/Study Hours\",\n",
        "    \"Academic Pressure\",\n",
        "    \"Work Pressure\",\n",
        "    \"Financial Stress\",\n",
        "]\n",
        "\n",
        "# Keep only columns that actually exist (prevents KeyErrors)\n",
        "numeric_cols_present = [c for c in numeric_features if c in df.columns]\n",
        "if not numeric_cols_present:\n",
        "    raise ValueError(\"None of the expected numeric columns are present to scale.\")\n",
        "\n",
        "# Coerce to numeric (if any are object dtype)\n",
        "for c in numeric_cols_present:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# Option A: Overwrite in place (common for modeling)\n",
        "scaler = StandardScaler()\n",
        "df[numeric_cols_present] = scaler.fit_transform(df[numeric_cols_present])\n",
        "\n",
        "# (Optional) Persist the scaler for later use (e.g., on test or production data)\n",
        "joblib.dump(scaler, \"scaler_standard.pkl\")\n",
        "print(\"Scaled columns:\", numeric_cols_present)\n",
        "print(\"Scaler saved to scaler_standard.pkl\")\n",
        "print(\"df shape after scaling:\", df.shape)\n",
        "\n",
        "# --------- OPTIONAL: Alternative that adds _scaled columns (keeps originals) ----------\n",
        "# mm = MinMaxScaler()\n",
        "# df[[c + \"_scaled\" for c in numeric_cols_present]] = mm.fit_transform(df[numeric_cols_present])\n",
        "# joblib.dump(mm, \"scaler_minmax.pkl\")\n",
        "# print(\"Also created MinMax-scaled copies with suffix _scaled.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# 1. Basic Info\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumn types:\\n\", df.dtypes)\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "\n",
        "\n",
        "# 6. Correlation Heatmap\n",
        "plt.figure(figsize=(10,6))\n",
        "# Select only numeric columns for correlation calculation\n",
        "numeric_df = df.select_dtypes(include=np.number)\n",
        "sns.heatmap(numeric_df.corr(), cmap=\"coolwarm\", center=0, annot=False)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zCOCk4VfvU9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}